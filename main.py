import os
import uuid
import datetime
from dotenv import load_dotenv
from fastapi import FastAPI, UploadFile, File, Body, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pymongo import MongoClient
from gridfs import GridFS, NoFile
from langchain_classic.memory import ConversationEntityMemory
from langchain_classic.chains import ConversationChain
from langchain_classic.prompts import PromptTemplate
from langchain_core.language_models.base import BaseLanguageModel
from langchain_core.outputs import LLMResult, Generation
import langextract as le
from PyPDF2 import PdfReader
from openpyxl import load_workbook

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
required_env_vars = ["MONGO_URI", "MONGO_DB_NAME"]
for var in required_env_vars:
    if not os.getenv(var):
        raise ValueError(f"ç¯å¢ƒå˜é‡ {var} æœªè®¾ç½®")

app = FastAPI(title="AIçº³ç•ŒåŠ©ç†", description="æ°¸ä¹…å­˜å‚¨/æ™ºèƒ½è®°å¿†/æ·±åº¦æ£€ç´¢/è‡ªç„¶è¯­è¨€æ“æ§/å¯¹è¯é¡µ")

# -------------------------- æ–°å¢ï¼šæ¨¡æ‹ŸLLMç±» --------------------------
class MockLLM(BaseLanguageModel):
    """ä¸€ä¸ªç®€å•çš„æ¨¡æ‹ŸLLMç±»ï¼Œç”¨äºæ»¡è¶³ConversationEntityMemoryçš„llmå‚æ•°è¦æ±‚"""
    
    def __init__(self):
        super().__init__()
    
    def generate_prompt(self, prompts, stop=None, callbacks=None, **kwargs):
        """æ¨¡æ‹Ÿç”Ÿæˆå›å¤ï¼Œè¿”å›ç©ºçš„å®ä½“ä¿¡æ¯"""
        generations = []
        for _ in prompts:
            # è¿”å›ç©ºçš„ç”Ÿæˆç»“æœï¼ŒConversationEntityMemoryéœ€è¦è¿™ä¸ªæ¥å£ä½†å®é™…ä¸Šä¸ä½¿ç”¨å®ƒçš„å†…å®¹
            generations.append([Generation(text="{}")])
        return LLMResult(generations=generations, llm_output={})
    
    async def agenerate_prompt(self, prompts, stop=None, callbacks=None, **kwargs):
        """å¼‚æ­¥æ¨¡æ‹Ÿç”Ÿæˆå›å¤ï¼Œè¿”å›ç©ºçš„å®ä½“ä¿¡æ¯"""
        return self.generate_prompt(prompts, stop, callbacks, **kwargs)
    
    def invoke(self, input, stop=None, callbacks=None, **kwargs):
        """å®ç°BaseLanguageModelè¦æ±‚çš„invokeæ–¹æ³•"""
        return "{}"
    
    async def ainvoke(self, input, stop=None, callbacks=None, **kwargs):
        """å®ç°BaseLanguageModelè¦æ±‚çš„å¼‚æ­¥ainvokeæ–¹æ³•"""
        return "{}"

# è·¨åŸŸé…ç½®ã€å‡çº§ã€‘ï¼šå‰ç«¯æœ¬åœ°è°ƒè¯•+ç”Ÿäº§ç¯å¢ƒå…¨å…¼å®¹
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ã€æ–°å¢æ ¸å¿ƒã€‘æ‰˜ç®¡é™æ€å‰ç«¯é¡µé¢ - è®¿é—® http://localhost:8000 ç›´æ¥æ‰“å¼€ä»¿è±†åŒ…å¯¹è¯é¡µ
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="static")

# -------------------------- 1. æ•°æ®åº“åˆå§‹åŒ– - MongoDB æ°¸ä¹…å­˜å‚¨ --------------------------
client = MongoClient(os.getenv("MONGO_URI"))
db = client[os.getenv("MONGO_DB_NAME")]
fs = GridFS(db)  # GridFSå­˜å‚¨å¤§æ–‡ä»¶ï¼šå›¾ç‰‡/éŸ³é¢‘/è§†é¢‘/PDF/Excelç­‰
# é›†åˆå®šä¹‰ï¼ˆæ‰€æœ‰æ•°æ®æ°¸ä¹…ä¿å­˜ï¼‰
col_chat_history = db["chat_history"]  # èŠå¤©è®°å½•
col_user_memory = db["user_memory"]    # ç”¨æˆ·å…³é”®è®°å¿†ï¼ˆçˆ±åƒé±¼ã€ä¸åƒè¾£ç­‰ï¼‰
col_file_meta = db["file_meta"]        # æ–‡ä»¶å…ƒä¿¡æ¯+æŠ½å–çš„å†…å®¹

# -------------------------- 2. LangChain æ ¸å¿ƒè®°å¿†ä½“ç³»åˆå§‹åŒ–ï¼ˆé‡ç‚¹ä¸å˜ï¼‰ --------------------------
# åˆ›å»ºæ¨¡æ‹ŸLLMå®ä¾‹
mock_llm = MockLLM()

# ä½¿ç”¨ConversationEntityMemoryä½œä¸ºå”¯ä¸€çš„è®°å¿†å¯¹è±¡
entity_memory = ConversationEntityMemory(
    entity_cache_limit=100,
    llm=mock_llm,
    human_prefix="ç”¨æˆ·",
    ai_prefix="AIåŠ©ç†"
)

MEMORY_PROMPT = PromptTemplate(
    input_variables=["input", "history", "entities"],
    template="""ä½ æ˜¯ç”¨æˆ·çš„ä¸“å±AIçº³ç•ŒåŠ©ç†ï¼Œæ‹¥æœ‰ç”¨æˆ·çš„å…¨éƒ¨é•¿æœŸè®°å¿†å’ŒçŸ¥è¯†åº“ï¼Œé£æ ¼å’Œè±†åŒ…ä¸€è‡´ï¼Œå›å¤ç®€æ´ç²¾å‡†å‹å¥½ã€‚
    1. ä½ éœ€è¦ä¸¥æ ¼è®°ä½ç”¨æˆ·çš„å®ä½“ä¿¡æ¯ï¼š{entities}ï¼ˆæ¯”å¦‚çˆ±åƒé±¼ã€ä¸åƒè¾£ã€å¿Œå£ã€å–œå¥½ç­‰ï¼Œæ‰€æœ‰å¯¹è¯å¿…é¡»å…³è”è¯¥è®°å¿†ï¼‰
    2. å‚è€ƒå†å²å¯¹è¯ä¸Šä¸‹æ–‡ï¼š{history}
    3. é’ˆå¯¹ç”¨æˆ·çš„é—®é¢˜/æŒ‡ä»¤ï¼š{input} è¿›è¡Œç²¾å‡†å›å¤ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€æ“æ§æ‰€æœ‰åŠŸèƒ½ã€‚
    è§„åˆ™ï¼šç”¨æˆ·çš„æ‰€æœ‰èµ„æ–™æ°¸ä¹…ä¿å­˜ï¼Œå¯éšæ—¶è°ƒå–ï¼›è‡ªåŠ¨æ•´ç†æ— æ•ˆæ–‡ä»¶ï¼›æå–å…³é”®è®°å¿†å¹¶æ°¸ä¹…ç”Ÿæ•ˆï¼›ä¸Šä¼ çš„æ–‡ä»¶è‡ªåŠ¨è§£æå†…å®¹å¹¶ä¿å­˜ã€‚
    å›å¤è¦æ±‚ï¼šå£è¯­åŒ–ã€æµç•…ï¼Œå’Œè±†åŒ…çš„å›å¤é£æ ¼ä¸€è‡´ï¼Œä¸è¦ç”Ÿç¡¬ï¼Œè®°å¿†å†…å®¹æ— ç¼èå…¥å›å¤ä¸­ã€‚
    """
)
conversation_chain = ConversationChain(
    memory=entity_memory,
    prompt=MEMORY_PROMPT,
    llm=mock_llm,
    verbose=True
)

# -------------------------- 3. å·¥å…·å‡½æ•°ï¼šæ–‡ä»¶å†…å®¹æå–+LangExtractä¿¡æ¯æ‹‰å– --------------------------
def extract_file_content(file: UploadFile, file_content: bytes) -> str:
    content = ""
    suffix = file.filename.split(".")[-1].lower() if "." in file.filename else ""
    try:
        if suffix in ["txt", "md", "json"]:
            content = file_content.decode("utf-8", errors="ignore")
        elif suffix == "pdf":
            try:
                # ä½¿ç”¨å·²è¯»å–çš„å†…å®¹åˆ›å»ºPdfReaderå¯¹è±¡
                from io import BytesIO
                pdf_reader = PdfReader(BytesIO(file_content))
                content = "\n".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])
            except Exception as e:
                print(f"PDFå†…å®¹æå–å¤±è´¥: {e}")
                content = f"[PDFæå–å¤±è´¥] {str(e)}"
        elif suffix in ["xlsx", "xls"]:
            try:
                from io import BytesIO
                wb = load_workbook(BytesIO(file_content))
                for sheet in wb.worksheets:
                    for row in sheet.iter_rows(values_only=True):
                        content += " ".join([str(cell) for cell in row if cell]) + "\n"
            except Exception as e:
                print(f"Excelå†…å®¹æå–å¤±è´¥: {e}")
                content = f"[Excelæå–å¤±è´¥] {str(e)}"
        elif suffix in ["jpg", "png", "jpeg", "gif"]:
            content = f"[{file.filename}] å›¾ç‰‡æ–‡ä»¶ï¼Œæ ¼å¼ï¼š{suffix}ï¼Œå¤§å°ï¼š{len(file_content)}å­—èŠ‚"
        elif suffix in ["mp4", "mp3", "avi", "mov", "wav"]:
            content = f"[{file.filename}] éŸ³è§†é¢‘æ–‡ä»¶ï¼Œæ ¼å¼ï¼š{suffix}ï¼Œå¤§å°ï¼š{len(file_content)}å­—èŠ‚"
        elif suffix in ["docx", "doc"]:
            try:
                from io import BytesIO
                from docx import Document
                doc = Document(BytesIO(file_content))
                content = "\n".join([paragraph.text for paragraph in doc.paragraphs])
            except ImportError:
                content = f"[{file.filename}] Wordæ–‡æ¡£ï¼Œå·²ä¿å­˜ï¼Œå†…å®¹å¯æ£€ç´¢ï¼ˆéœ€è¦å®‰è£…python-docxåº“ä»¥æå–å†…å®¹ï¼‰"
            except Exception as e:
                print(f"Wordå†…å®¹æå–å¤±è´¥: {e}")
                content = f"[{file.filename}] Wordæ–‡æ¡£ï¼Œå·²ä¿å­˜ï¼Œå†…å®¹æå–å¤±è´¥: {str(e)}"
        
        # LangExtractæ ¸å¿ƒæå–ï¼šæ¸…æ´—+æç‚¼å…³é”®ä¿¡æ¯
        if content:
            content = le.extract(content, extract_type="text", clean=True)
    except Exception as e:
        print(f"æ–‡ä»¶å†…å®¹æå–å¤±è´¥: {e}")
        content = f"[æ–‡ä»¶æå–å¤±è´¥] {str(e)}"
    return content

# -------------------------- 4. æ–°å¢ï¼šå‰ç«¯é¦–é¡µè·¯ç”±ï¼ˆè®¿é—®æ ¹ç›®å½•æ‰“å¼€ä»¿è±†åŒ…å¯¹è¯é¡µï¼‰ --------------------------
@app.get("/", summary="ä»¿è±†åŒ…é£æ ¼çš„AIçº³ç•ŒåŠ©ç†å¯¹è¯é¦–é¡µ")
async def index(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

# -------------------------- 5. æ ¸å¿ƒAPIæ¥å£ï¼ˆå…¨éƒ¨ä¿ç•™+ä¼˜åŒ–é€‚é…å‰ç«¯ï¼‰ --------------------------
@app.post("/save_all", summary="æ ¸å¿ƒæ¥å£ï¼šå‘é€ä»»æ„å†…å®¹/æ–‡ä»¶ç»™AIï¼Œæ°¸ä¹…ä¿å­˜+è‡ªåŠ¨æ•´ç†")
async def save_everything(
    content: str = Body(default="", description="æ–‡æœ¬å†…å®¹ï¼šæ—¥è®°/èµ„æ–™/æ–‡å­—ä¿¡æ¯"),
    files: list[UploadFile] = File(default=[], description="ä¸Šä¼ æ–‡ä»¶ï¼šå›¾ç‰‡/éŸ³é¢‘/è§†é¢‘/PDF/Excel/æ‰€æœ‰æ ¼å¼")
):
    user_id = "user_001"
    save_id = str(uuid.uuid4())
    create_time = datetime.datetime.now()
    
    try:
        if content.strip():
            core_content = le.extract(content, extract_type="summary", max_length=500)
            col_file_meta.insert_one({
                "save_id": save_id,
                "user_id": user_id,
                "type": "text",
                "content": content,
                "core_content": core_content,
                "filename": "æ–‡æœ¬ç¬”è®°/æ—¥è®°",
                "create_time": create_time,
                "is_valid": True
            })
        
        file_list = []
        for file in files:
            try:
                # åªè¯»å–ä¸€æ¬¡æ–‡ä»¶å†…å®¹
                file_content = await file.read()
                file_id = fs.put(file_content, filename=file.filename, content_type=file.content_type)
                extract_content = extract_file_content(file, file_content)
                col_file_meta.insert_one({
                    "save_id": save_id,
                    "user_id": user_id,
                    "type": "file",
                    "file_id": file_id,
                    "filename": file.filename,
                    "content": extract_content,
                    "create_time": create_time,
                    "is_valid": True
                })
                file_list.append(file.filename)
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {file.filename} å¤±è´¥: {e}")
                return JSONResponse(status_code=500, content={"code": 500, "msg": f"å¤„ç†æ–‡ä»¶ {file.filename} å¤±è´¥: {str(e)}"})
        
        # æ›´æ–°è®°å¿†
        conversation_chain.predict(input=f"ä¿å­˜èµ„æ–™ï¼š{content}ï¼Œä¸Šä¼ æ–‡ä»¶ï¼š{file_list}")
        
        return {
            "code": 200,
            "msg": "âœ… æ‰€æœ‰å†…å®¹å·²æ°¸ä¹…ä¿å­˜+AIè‡ªåŠ¨æ•´ç†å®Œæˆ",
            "data": {"save_id": save_id, "create_time": str(create_time), "files": file_list}
        }
    except Exception as e:
        print(f"ä¿å­˜å†…å®¹å¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"code": 500, "msg": f"ä¿å­˜å†…å®¹å¤±è´¥: {str(e)}"})

@app.post("/retrieve", summary="æ ¸å¿ƒæ¥å£ï¼šè‡ªç„¶è¯­è¨€è°ƒå–èµ„æ–™ï¼ˆæ·±åº¦æ£€ç´¢+æ—¶é—´æ£€ç´¢+å†…å®¹æ£€ç´¢ï¼‰")
async def retrieve_info(query: str = Body(..., description="è‡ªç„¶è¯­è¨€æ£€ç´¢æŒ‡ä»¤"),
                        start_time: str = Body(default=None),
                        end_time: str = Body(default=None)):
    user_id = "user_001"
    query_filter = {"user_id": user_id, "is_valid": True}
    
    try:
        if start_time and end_time:
            try:
                start_dt = datetime.datetime.fromisoformat(start_time)
                end_dt = datetime.datetime.fromisoformat(end_time)
                query_filter["create_time"] = {"$gte": start_dt, "$lte": end_dt}
            except ValueError as e:
                return JSONResponse(status_code=400, content={"code": 400, "msg": f"æ—¶é—´æ ¼å¼é”™è¯¯: {str(e)}"})
        
        all_docs = list(col_file_meta.find(query_filter))
        match_docs = [doc for doc in all_docs if query in doc.get("content", "") or query in doc.get("filename", "")]
        chat_docs = list(col_chat_history.find({"user_id": user_id, "user_msg": {"$regex": query}}))
        
        entity_info = entity_memory.entity_store.store
        memory_prompt = f"ç”¨æˆ·å…³é”®è®°å¿†ï¼š{entity_info}ï¼Œæ£€ç´¢éœ€æ±‚ï¼š{query}"
        ai_response = conversation_chain.predict(input=memory_prompt)
        
        return {
            "code": 200,
            "msg": "æ£€ç´¢å®Œæˆï¼Œå·²å…³è”ä½ çš„é•¿æœŸå…³é”®è®°å¿†",
            "data": {
                "user_memory": entity_info,
                "match_files": match_docs,
                "match_chat": chat_docs,
                "ai_summary": ai_response
            }
        }
    except Exception as e:
        print(f"æ£€ç´¢å¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"code": 500, "msg": f"æ£€ç´¢å¤±è´¥: {str(e)}"})

@app.post("/chat", summary="èŠå¤©+è®°å¿†+æ±‡æ€»ä¿å­˜ï¼šæ ¸å¿ƒå¯¹è¯æ¥å£ï¼Œä»¿è±†åŒ…å›å¤é£æ ¼")
async def chat_with_assistant(message: str = Body(..., description="ç”¨æˆ·å¯¹è¯/æŒ‡ä»¤")):
    user_id = "user_001"
    create_time = datetime.datetime.now()
    
    try:
        # æ ¸å¿ƒï¼šLangChainå¯¹è¯+è®°å¿†æ›´æ–°ï¼Œè±†åŒ…é£æ ¼å›å¤
        ai_reply = conversation_chain.predict(input=message)
        
        # æŒ‡ä»¤å¤„ç†ï¼šåˆ é™¤æ— æ•ˆæ–‡ä»¶/æ±‡æ€»èµ„æ–™/æå–è®°å¿†
        if any(key in message for key in ["åˆ é™¤æ— æ•ˆæ–‡ä»¶", "æ¸…ç†åƒåœ¾æ–‡ä»¶", "åˆ é™¤ç©ºæ–‡ä»¶"]):
            col_file_meta.update_many({"content": "", "filename": {"$regex": "æ— å†…å®¹"}}, {"$set": {"is_valid": False}})
            ai_reply += "\nâœ… å·²è‡ªåŠ¨æ¸…ç†æ‰€æœ‰æ— æ•ˆ/ç©ºæ–‡ä»¶ï¼Œæ ‡è®°ä¸ºå¤±æ•ˆçŠ¶æ€"
        
        if any(key in message for key in ["æ±‡æ€»ä¿å­˜", "æ•´ç†èµ„æ–™", "æ±‡æ€»æˆ‘çš„æ‰€æœ‰èµ„æ–™"]):
            all_valid_docs = list(col_file_meta.find({"user_id": user_id, "is_valid": True}))
            summary = le.extract(str(all_valid_docs), extract_type="summary", max_length=1000)
            col_file_meta.insert_one({
                "user_id": user_id,
                "type": "summary",
                "content": summary,
                "filename": "èµ„æ–™æ±‡æ€»-" + str(create_time.date()),
                "create_time": create_time,
                "is_valid": True
            })
            ai_reply += f"\nâœ… å·²æ±‡æ€»ä½ æ‰€æœ‰çš„æœ‰æ•ˆèµ„æ–™å¹¶æ°¸ä¹…ä¿å­˜ï¼Œå…±æ•´ç† {len(all_valid_docs)} æ¡å†…å®¹"
        
        if any(key in message for key in ["æå–å…³é”®è®°å¿†", "æˆ‘çš„è®°å¿†", "æˆ‘æœ‰å“ªäº›åå¥½"]):
            ai_reply = f"ğŸ“Œ ä½ çš„é•¿æœŸå…³é”®è®°å¿†ï¼š{entity_memory.entity_store.store}\n\n{ai_reply}"
        
        # èŠå¤©è®°å½•æ°¸ä¹…ä¿å­˜
        col_chat_history.insert_one({
            "user_id": user_id,
            "user_msg": message,
            "ai_reply": ai_reply,
            "create_time": create_time
        })
        
        # å…³é”®è®°å¿†æŒä¹…åŒ–
        col_user_memory.update_one(
            {"user_id": user_id},
            {"$set": {"memory": entity_memory.entity_store.store, "update_time": create_time}},
            upsert=True
        )
        
        return {
            "code": 200,
            "user_msg": message,
            "ai_reply": ai_reply,
            "your_key_memory": entity_memory.entity_store.store,
            "create_time": str(create_time)
        }
    except Exception as e:
        print(f"èŠå¤©å¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"code": 500, "msg": f"èŠå¤©å¤±è´¥: {str(e)}"})

@app.post("/load_memory", summary="é‡å¯æœåŠ¡ååŠ è½½é•¿æœŸè®°å¿†ï¼šä¿è¯è®°å¿†æ°¸ä¸ä¸¢å¤±")
async def load_user_memory():
    user_id = "user_001"
    try:
        memory_doc = col_user_memory.find_one({"user_id": user_id})
        if memory_doc:
            entity_memory.entity_store.store = memory_doc["memory"]
            return {"code": 200, "msg": "âœ… é•¿æœŸå…³é”®è®°å¿†åŠ è½½å®Œæˆ", "memory": memory_doc["memory"]}
        return {"code": 200, "msg": "âœ… æš‚æ— é•¿æœŸè®°å¿†ï¼Œå¼€å§‹ç§¯ç´¯ä½ çš„ä¸“å±è®°å¿†å§ï½"}
    except Exception as e:
        print(f"åŠ è½½è®°å¿†å¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"code": 500, "msg": f"åŠ è½½è®°å¿†å¤±è´¥: {str(e)}"})

# -------------------------- æ–°å¢ï¼šæ–‡ä»¶ä¸‹è½½æ¥å£ï¼ˆå‰ç«¯å¯ç›´æ¥ä¸‹è½½ä¸Šä¼ çš„æ–‡ä»¶ï¼‰ --------------------------
@app.post("/download_file", summary="ä¸‹è½½å·²ä¿å­˜çš„æ–‡ä»¶")
async def download_file(file_id: str = Body(..., description="æ–‡ä»¶ID")):
    try:
        file = fs.get(file_id)
        return StreamingResponse(file, media_type=file.content_type, headers={"Content-Disposition": f"attachment; filename={file.filename}"})
    except NoFile:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    except Exception as e:
        print(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
        return JSONResponse(status_code=500, content={"code": 500, "msg": f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}"})

# -------------------------- å¯åŠ¨æœåŠ¡ --------------------------
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=int(os.getenv("PORT", 8000)), reload=True)